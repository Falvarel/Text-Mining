{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svuzsW-c_Va0"
   },
   "source": [
    "# Text Mining - Clasificacion textos\n",
    "\n",
    "### Source: Andrew Task, Udacity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5Y0tolWGdIo"
   },
   "source": [
    "### 1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAb08gTYNV7h",
    "outputId": "2f3d579d-5d79-49c5-f3cc-8c8709cd453d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "lSsxGwKdNUUf",
    "outputId": "3beec9c9-bb1b-4342-f376-869dbcbe0e34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-37ee28f4-c161-4d8b-a9d9-5339a2a30e05\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-37ee28f4-c161-4d8b-a9d9-5339a2a30e05\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reviews.txt to reviews.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "_A0guXOO1zhr",
    "outputId": "407146c0-5ffb-4935-d883-5e954550a853"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-d2e90b1e-6765-49d7-867b-0879d61ea1e8\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-d2e90b1e-6765-49d7-867b-0879d61ea1e8\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reviews.txt to reviews (1).txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqOmYFCU_caw"
   },
   "outputs": [],
   "source": [
    "## Críticas de películas\n",
    "#g = open('/content/drive/My Drive/Colab Notebooks/AFI/Text Mining/reviews.txt','r') # What we WANT to know!\n",
    "g = open('/content/reviews.txt','r') \n",
    "reviews = g.read().splitlines()\n",
    "g.close()\n",
    "\n",
    "## Sentimiento asociado\n",
    "#g = open('/content/drive/My Drive/Colab Notebooks/AFI/Text Mining/labels.txt','r') # What we WANT to know!\n",
    "g = open('/content/labels.txt','r') # What we WANT to know!\n",
    "labels = g.read().upper().splitlines()\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCNRyZge_q-S",
    "outputId": "25f0fda8-a148-4051-ee7a-7d26b83f0574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "m4-aZ98KApvE",
    "outputId": "8ddf80fa-bb07-4daa-c34b-e8203a3f8c84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Sp0eh4FAgAm",
    "outputId": "8d26667f-a0af-4594-f928-95d19c9fba8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xsYwZbY8Alu3",
    "outputId": "fcc79a8f-f4dc-48bf-e81f-8cd99074ee2d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NnpYsu8b9-9"
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uZIkLHR-658",
    "nbpresent": {
     "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
    },
    "outputId": "82e78f3d-469c-486e-cba6-90fc49ec11df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
      "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
      "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
      "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
      "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)\n",
    "pretty_print_review_and_label(6267)\n",
    "pretty_print_review_and_label(21934)\n",
    "pretty_print_review_and_label(5297)\n",
    "pretty_print_review_and_label(4998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLGTusxtGV87"
   },
   "source": [
    "### 2. Análisis cuantitativo términos: ¿Qué términos aparecen en los comentarios positivos, cuales en los negativos y cuales aparecen en ambos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlqB8_qn-66C"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M91OwP4ecNyN"
   },
   "source": [
    "Vamos a utilizar la estructura Counter de python para ver cuantas veces aparece cada palabra en las críticas. Debajo tienes un ejemplo de como utilizar un contador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbZsxhiYcvuc"
   },
   "source": [
    "https://docs.python.org/2/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5zuEETgcXD2",
    "outputId": "17de314a-4e8c-4f02-a446-80fadf003b9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('palabra2', 5), ('coche', 3)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_count = Counter()\n",
    "ex_count['coche'] = 3\n",
    "ex_count['palabra2'] = 5\n",
    "ex_count.most_common()\n",
    "\n",
    "# objeto \"Counter()\" de la librería colección sirve para crear lista de tuplas\n",
    "# en este caso lo vamos a utilizar para crear una lista de tuplas con key=palabra y value=frecuencia palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrNcZkIpGmT1"
   },
   "outputs": [],
   "source": [
    "# Un contandor para cada tipo de review y uno total\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbU5hbuzHRQ9"
   },
   "outputs": [],
   "source": [
    "# Crea un bucle que, para cada crítica, recorra sus palabras una a una e incremente en 1 el número de aparaciones.\n",
    "# Aumenta el contador siempre en total_counts y en positive_counts O en negative_counts dependiendo de si es una crítica\n",
    "# positiva o negativa\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "  if(labels[i] == \"POSITIVE\"):\n",
    "    for word in reviews[i].split(\" \"):\n",
    "      positive_counts[word] += 1\n",
    "      total_counts[word] +=1\n",
    "  else:\n",
    "    for word in reviews[i].split(\" \"):\n",
    "      negative_counts[word] += 1\n",
    "      total_counts[word] +=1\n",
    "\n",
    "# recorremos todas las reviews, clasificamos negativas y positivas\n",
    "# para cada tipo recorremos las palabras de cada crítica y creamos objeto \"Counter()\" (lista de tuplas) \n",
    "# con key=palabra y value=frecuencia palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJ34GLuPjeUz"
   },
   "outputs": [],
   "source": [
    "ex_count = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqYOeZ25jdGa",
    "outputId": "31c9d4dd-5900-4f77-d043-abbad231e9f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coche', 11), ('palabra2', 5)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_count['coche'] += 3\n",
    "ex_count['coche'] += 1\n",
    "ex_count['coche'] += 7\n",
    "ex_count['palabra2'] = 5\n",
    "ex_count.most_common()\n",
    "\n",
    "# objeto \"Counter()\" de la librería colección sirve para crear lista de tuplas\n",
    "# en este caso lo vamos a utilizar para crear una lista de tuplas con key=palabra y value=frecuencia palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IX6QYAZAHWKA",
    "outputId": "4f849ca6-9f7f-49ed-8c6d-f23f02e9a82f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 550468),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9jcE5CGbZab",
    "outputId": "1e356943-a006-4914-8622-6d612ace8eb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 561462),\n",
       " ('.', 167538),\n",
       " ('the', 163389),\n",
       " ('a', 79321),\n",
       " ('and', 74385),\n",
       " ('of', 69009),\n",
       " ('to', 68974),\n",
       " ('br', 52637),\n",
       " ('is', 50083),\n",
       " ('it', 48327)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_counts.most_common(10)\n",
    "\n",
    "# más comunes son \"stopwords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56UEs2mpbZlA",
    "outputId": "c8f71fc7-e368-49d8-c0e4-73ca3f75a339"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1111930),\n",
       " ('the', 336713),\n",
       " ('.', 327192),\n",
       " ('and', 164107),\n",
       " ('a', 163009),\n",
       " ('of', 145864),\n",
       " ('to', 135720),\n",
       " ('is', 107328),\n",
       " ('br', 101872),\n",
       " ('it', 96352)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.most_common(10)\n",
    "\n",
    "# más comunes son \"stopwords\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeZvc1p6dj84"
   },
   "source": [
    "El resultado del conteo muestra que las stopwords están presentes tanto en críticas positivas como en críticas negativas y pueden añadir ruido a la hora crear un modelo de clasificación. ¿Cómo podemos sacar aquellas palabras que son un indicador claro de que se trata de una crítica positiva o negativa? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viJr7UXGeVbu"
   },
   "source": [
    "### 3. Análisis cuantitativo términos: Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmhHY4jvek4X"
   },
   "source": [
    "Vamos a calcular los ratios de aparición de los términos de la siguiente manera: ratio = positive_counts/float(negative_counts + 1).\n",
    "\n",
    "**Nota**: vamos a trabajar unicamente con aquellos términos que **en total** aparecen 101 o más veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDOywUqOfDli"
   },
   "source": [
    "*   ¿Por qué ese +1 en el denominador?\n",
    "*   A bote pronto, ¿cómo interpretaríamos los resultados? ¿En qué rango se van a mover los ratios?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktFv5uKydaCP"
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "# Calcula el ratio para los término más comunes\n",
    "for term, cnt in list(total_counts.most_common()):\n",
    "  if(cnt > 100):\n",
    "    pos_neg_ratios[term] = positive_counts[term] / float(negative_counts[term]+1)\n",
    "\n",
    "# en la lista \"total_counts\" anterior (lista de tuplas con todas las palabras del conjunto de textos = vocabulario)\n",
    "# recorro la lista de tuplas comprobando condición de que su frecuencia sea mayor de 101\n",
    "# en caso de cumplir condición, sacar valor que queremos calcular\n",
    "\n",
    "# \"float()\" lo ponemos para asegurarnos de que nos devuelve los decimales de la división"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2BnMZPsf3_7",
    "outputId": "c6c40c75-1459-43d4-eb4f-1cb90b0fdcd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 109.0),\n",
       " ('paulie', 59.0),\n",
       " ('felix', 23.4),\n",
       " ('polanski', 16.833333333333332),\n",
       " ('matthau', 16.555555555555557),\n",
       " ('victoria', 14.6),\n",
       " ('mildred', 13.5),\n",
       " ('gandhi', 12.666666666666666),\n",
       " ('flawless', 11.6),\n",
       " ('superbly', 9.583333333333334),\n",
       " ('perfection', 8.666666666666666),\n",
       " ('astaire', 8.5),\n",
       " ('captures', 7.68),\n",
       " ('voight', 7.615384615384615),\n",
       " ('wonderfully', 7.552631578947368)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common(15)\n",
    "\n",
    "# palabras con valores mayores = palabras \"positivas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVQ2eL6j-66Z",
    "outputId": "7d360447-1f98-4566-af66-2decc0711358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
      "Pos-to-neg ratio for 'amazing' = 4.022813688212928\n",
      "Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"
     ]
    }
   ],
   "source": [
    "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))\n",
    "\n",
    "# palabras en ambos tipos de reviews (\"stopwords\" o palabras genéricas sobre el tema) / valor = 1\n",
    "# palabras en reviews positivas / valor >>> 1\n",
    "# palabras en reviews negativas / valor = 0\n",
    "\n",
    "# PROBLEMAS DE ESCALADO:\n",
    "# el problema con esta valoración de las palabras es que el espacio para las palabras negativas es muy pequeño [0,1) en\n",
    "# comparación con el de las palabras positivas (1,infinito)\n",
    "\n",
    "# si le damos los valores así a un modelo, es muy probable que se vea influenciado por el mayor orden de los valores \n",
    "# positivos y puede que no funcione correctamente\n",
    "\n",
    "# Lo corregimos aplicando logaritmos:\n",
    "#  - valores (0,1) = valor negativo\n",
    "#  - valor (1) = 0\n",
    "#  - valores >>> 1 = valor (0,infinito)  pero va a reducir logaritmicamente el orden de los valores anteriores\n",
    "# conseguimos igualar/normalizar los valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaRceyK0gTdi"
   },
   "source": [
    "¿Qué problema tiene esta definición de ratio? ¿Cómo lo solucionamos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CquUDSegmpV"
   },
   "source": [
    "### 4. Análisis cuantitativo términos: Logaritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEFWetNNg2pR"
   },
   "source": [
    "Al aplicar logaritmos a los valores calculados en el apartado anterior hacemos que los valores por debajo de 1 pasen a ser negativos (y con valor absoluto más alto cuanto más cercanos a 0 sean) y además conseguimos que dos términos con frecuencias relativas parecidas pero en críticas de signo distinto tomen valores con valor absoluto parecido y signo contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6SwM1-5-66d"
   },
   "outputs": [],
   "source": [
    "# Calcula el logaritmo de los ratios para todos los términos\n",
    "for term, ratio in list(pos_neg_ratios.most_common()):\n",
    "  pos_neg_ratios[term] = np.log(ratio)\n",
    "\n",
    "# recorremos lista de valores calculados anteriormente y sustituimos el valor por el logaritmo del valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nelsu3orhrz_",
    "outputId": "841a46e2-755a-403a-c8c2-9583fc3b8305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.07753744390572),\n",
       " ('felix', 3.152736022363656),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.80672172860924),\n",
       " ('victoria', 2.681021528714291),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.538973871058276),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.26002547857525),\n",
       " ('perfection', 2.159484249353372),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.038619547159581),\n",
       " ('voight', 2.030170492673053),\n",
       " ('wonderfully', 2.0218960560332353)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac4dUOgEhnML",
    "outputId": "332f8bf1-983a-47db-9636-b2ad0fffe45b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
      "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
      "Pos-to-neg ratio for 'terrible' = -1.7291085042663878\n"
     ]
    }
   ],
   "source": [
    "## Algunos ejemplos que nos ayudan a interpretar los resultados\n",
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))\n",
    "\n",
    "# palabras en ambos tipos de reviews (\"stopwords\" o palabras genéricas sobre el tema) / valor = 0\n",
    "# palabras en reviews positivas / valor > 0\n",
    "# palabras en reviews negativas / valor < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuwnIl_Wh8e5",
    "outputId": "58fd434b-72dc-435b-db71-5feae1d40ccd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boll', -4.969813299576001),\n",
       " ('uwe', -4.624972813284271),\n",
       " ('seagal', -3.644143560272545),\n",
       " ('unwatchable', -3.258096538021482),\n",
       " ('stinker', -3.2088254890146994),\n",
       " ('mst', -2.9502698994772336),\n",
       " ('incoherent', -2.9368917735310576),\n",
       " ('unfunny', -2.6922395950755678),\n",
       " ('waste', -2.6193845640165536),\n",
       " ('blah', -2.5704288232261625),\n",
       " ('horrid', -2.4849066497880004),\n",
       " ('pointless', -2.4553061800117097),\n",
       " ('atrocious', -2.4259083090260445),\n",
       " ('redeeming', -2.3682390632154826),\n",
       " ('prom', -2.3608540011180215),\n",
       " ('drivel', -2.3470368555648795),\n",
       " ('lousy', -2.307572634505085),\n",
       " ('worst', -2.286987896180378),\n",
       " ('laughable', -2.264363880173848),\n",
       " ('awful', -2.227194247027435),\n",
       " ('poorly', -2.2207550747464135),\n",
       " ('wasting', -2.204604684633842),\n",
       " ('remotely', -2.1972245773362196),\n",
       " ('existent', -2.0794415416798357),\n",
       " ('boredom', -1.995100393246085),\n",
       " ('miserably', -1.9924301646902063),\n",
       " ('sucks', -1.987068221548821),\n",
       " ('uninspired', -1.9832976811269336),\n",
       " ('lame', -1.981767458946166),\n",
       " ('insult', -1.978345424808467)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common()[:-31:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hdAIKBvJEKa"
   },
   "source": [
    "### 5. Modelo de clasificación basado en bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD8mLKkKJOaL"
   },
   "source": [
    "Vamos a aplicar la técnica de bag of words paso a paso a cada una de las críticas con el objetivo de convertirlas en vectores numéricos que sirvan de features de un nuestro modelo.\n",
    "\n",
    "#### Primer paso: construir el conjunto de palabras de nuestros vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbWDpvonhp7n"
   },
   "outputs": [],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "\n",
    "# creamos vocabulario con todas las palabras de la lista que calculamos \"total_counts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASu4GwbSJt_u",
    "outputId": "59164a6b-50cf-4983-d8e9-57d6e687d987"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74074"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeneoUAXKRe5"
   },
   "source": [
    "#### Segundo paso: construímos un vector del tamaño de nuestro vocabulario. Para ganar tiempo lo creamos como un vector entero de 0s usando la función de numpy zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re4cRsBcJy9L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "zeros = np.zeros(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwlXPMQUKMSp",
    "outputId": "07f684e3-9246-40f2-f64f-4893bdbf2518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-wjmc3TKl7n"
   },
   "source": [
    "#### Tercer paso: asignar a cada palabra un índice del vector y crear una tabla maestra que guarde esta relación y nos permita crear fácilmente nuestros vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyTGXExmKOto",
    "outputId": "cbab43cc-5c09-4b80-9f3c-9bc4776d0a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'klown': 1,\n",
       " 'treck': 2,\n",
       " 'polson': 3,\n",
       " 'items': 4,\n",
       " 'remedios': 5,\n",
       " 'culpability': 6,\n",
       " 'hurt': 7,\n",
       " 'barbs': 8,\n",
       " 'camped': 9,\n",
       " 'sudser': 10,\n",
       " 'olivier': 11,\n",
       " 'fancies': 12,\n",
       " 'jaques': 13,\n",
       " 'beaute': 14,\n",
       " 'eradicate': 15,\n",
       " 'hoyo': 16,\n",
       " 'dickinsons': 17,\n",
       " 'twilight': 18,\n",
       " 'beeline': 19,\n",
       " 'feuds': 20,\n",
       " 'ghulam': 21,\n",
       " 'heidi': 22,\n",
       " 'runaways': 23,\n",
       " 'carlas': 24,\n",
       " 'fulfilled': 25,\n",
       " 'pancreatitis': 26,\n",
       " 'janikowski': 27,\n",
       " 'skanky': 28,\n",
       " 'minbari': 29,\n",
       " 'vail': 30,\n",
       " 'cannes': 31,\n",
       " 'whistlestop': 32,\n",
       " 'douses': 33,\n",
       " 'crevice': 34,\n",
       " 'rodder': 35,\n",
       " 'besxt': 36,\n",
       " 'mansion': 37,\n",
       " 'menace': 38,\n",
       " 'counteract': 39,\n",
       " 'homoeroticism': 40,\n",
       " 'captioning': 41,\n",
       " 'declares': 42,\n",
       " 'paglia': 43,\n",
       " 'mirroed': 44,\n",
       " 'reginald': 45,\n",
       " 'itelf': 46,\n",
       " 'crystin': 47,\n",
       " 'trivialia': 48,\n",
       " 'thickly': 49,\n",
       " 'dasilva': 50,\n",
       " 'slept': 51,\n",
       " 'mancini': 52,\n",
       " 'jungian': 53,\n",
       " 'buckaroos': 54,\n",
       " 'semite': 55,\n",
       " 'burglarize': 56,\n",
       " 'metroid': 57,\n",
       " 'meyers': 58,\n",
       " 'sinnister': 59,\n",
       " 'bill': 60,\n",
       " 'appalingly': 61,\n",
       " 'assimilation': 62,\n",
       " 'ughhhh': 63,\n",
       " 'potentials': 64,\n",
       " 'persian': 65,\n",
       " 'woodcuts': 66,\n",
       " 'eclipses': 67,\n",
       " 'napier': 68,\n",
       " 'teenies': 69,\n",
       " 'bluish': 70,\n",
       " 'martialed': 71,\n",
       " 'decadents': 72,\n",
       " 'technique': 73,\n",
       " 'eliana': 74,\n",
       " 'pledge': 75,\n",
       " 'interminably': 76,\n",
       " 'publicdomain': 77,\n",
       " 'starrer': 78,\n",
       " 'nastassja': 79,\n",
       " 'amnesiac': 80,\n",
       " 'tooms': 81,\n",
       " 'deedee': 82,\n",
       " 'subconsciously': 83,\n",
       " 'vaporizes': 84,\n",
       " 'donning': 85,\n",
       " 'federally': 86,\n",
       " 'tenacious': 87,\n",
       " 'strewn': 88,\n",
       " 'maximises': 89,\n",
       " 'goldwyn': 90,\n",
       " 'lb': 91,\n",
       " 'tankentai': 92,\n",
       " 'petey': 93,\n",
       " 'unions': 94,\n",
       " 'bodyguards': 95,\n",
       " 'ineptly': 96,\n",
       " 'sic': 97,\n",
       " 'bergeron': 98,\n",
       " 'ulfinal': 99,\n",
       " 'childbirth': 100,\n",
       " 'vh': 101,\n",
       " 'naushad': 102,\n",
       " 'directeur': 103,\n",
       " 'sharper': 104,\n",
       " 'ungenerous': 105,\n",
       " 'worthiness': 106,\n",
       " 'maxx': 107,\n",
       " 'punsley': 108,\n",
       " 'explores': 109,\n",
       " 'funding': 110,\n",
       " 'alliances': 111,\n",
       " 'innate': 112,\n",
       " 'debbie': 113,\n",
       " 'romanticised': 114,\n",
       " 'blackouts': 115,\n",
       " 'piraters': 116,\n",
       " 'camels': 117,\n",
       " 'tanny': 118,\n",
       " 'turnaround': 119,\n",
       " 'windlass': 120,\n",
       " 'delicate': 121,\n",
       " 'silverlake': 122,\n",
       " 'unstrung': 123,\n",
       " 'councilors': 124,\n",
       " 'finacee': 125,\n",
       " 'buxom': 126,\n",
       " 'critially': 127,\n",
       " 'aap': 128,\n",
       " 'pork': 129,\n",
       " 'depardeu': 130,\n",
       " 'darren': 131,\n",
       " 'nacio': 132,\n",
       " 'gia': 133,\n",
       " 'happpeniiiinngggg': 134,\n",
       " 'trowa': 135,\n",
       " 'westcourt': 136,\n",
       " 'balcony': 137,\n",
       " 'unpatriotic': 138,\n",
       " 'doan': 139,\n",
       " 'ottaviano': 140,\n",
       " 'mortgages': 141,\n",
       " 'growers': 142,\n",
       " 'travis': 143,\n",
       " 'greenblatt': 144,\n",
       " 'rochefort': 145,\n",
       " 'packet': 146,\n",
       " 'mongooses': 147,\n",
       " 'enrichment': 148,\n",
       " 'anecdotal': 149,\n",
       " 'harra': 150,\n",
       " 'brommell': 151,\n",
       " 'dailey': 152,\n",
       " 'vacate': 153,\n",
       " 'accusations': 154,\n",
       " 'humanely': 155,\n",
       " 'katryn': 156,\n",
       " 'backlot': 157,\n",
       " 'mimetic': 158,\n",
       " 'nunns': 159,\n",
       " 'pedophiliac': 160,\n",
       " 'bombarded': 161,\n",
       " 'himmler': 162,\n",
       " 'disconcerted': 163,\n",
       " 'hawked': 164,\n",
       " 'blackguard': 165,\n",
       " 'sacrificies': 166,\n",
       " 'mountaineering': 167,\n",
       " 'personifying': 168,\n",
       " 'lorenzo': 169,\n",
       " 'alwin': 170,\n",
       " 'sacrament': 171,\n",
       " 'maoist': 172,\n",
       " 'clubbing': 173,\n",
       " 'tasks': 174,\n",
       " 'morrow': 175,\n",
       " 'intergroup': 176,\n",
       " 'hedlund': 177,\n",
       " 'psychotherapist': 178,\n",
       " 'magnum': 179,\n",
       " 'framework': 180,\n",
       " 'ammmmm': 181,\n",
       " 'topicstolen': 182,\n",
       " 'simulations': 183,\n",
       " 'psychoses': 184,\n",
       " 'heinously': 185,\n",
       " 'swoosie': 186,\n",
       " 'merchandising': 187,\n",
       " 'putnam': 188,\n",
       " 'dary': 189,\n",
       " 'distortions': 190,\n",
       " 'emilie': 191,\n",
       " 'shrewed': 192,\n",
       " 'degenerates': 193,\n",
       " 'roby': 194,\n",
       " 'bulu': 195,\n",
       " 'ebullient': 196,\n",
       " 'graduating': 197,\n",
       " 'observer': 198,\n",
       " 'cavalli': 199,\n",
       " 'facing': 200,\n",
       " 'forementioned': 201,\n",
       " 'noggin': 202,\n",
       " 'kph': 203,\n",
       " 'mantraps': 204,\n",
       " 'marienbad': 205,\n",
       " 'tidey': 206,\n",
       " 'landings': 207,\n",
       " 'dighton': 208,\n",
       " 'pics': 209,\n",
       " 'medias': 210,\n",
       " 'shun': 211,\n",
       " 'dubber': 212,\n",
       " 'parrots': 213,\n",
       " 'northt': 214,\n",
       " 'arid': 215,\n",
       " 'scream': 216,\n",
       " 'granger': 217,\n",
       " 'vingana': 218,\n",
       " 'bickle': 219,\n",
       " 'dual': 220,\n",
       " 'fashionthat': 221,\n",
       " 'rakes': 222,\n",
       " 'prodigal': 223,\n",
       " 'kinka': 224,\n",
       " 'scrupulously': 225,\n",
       " 'infect': 226,\n",
       " 'all': 227,\n",
       " 'stalagmite': 228,\n",
       " 'unmotivated': 229,\n",
       " 'masseur': 230,\n",
       " 'palagi': 231,\n",
       " 'ladislav': 232,\n",
       " 'epidemic': 233,\n",
       " 'threading': 234,\n",
       " 'stevie': 235,\n",
       " 'presto': 236,\n",
       " 'bensonhurst': 237,\n",
       " 'pamby': 238,\n",
       " 'boredom': 239,\n",
       " 'jarols': 240,\n",
       " 'ang': 241,\n",
       " 'pacifistic': 242,\n",
       " 'lunes': 243,\n",
       " 'swashbuckling': 244,\n",
       " 'rival': 245,\n",
       " 'carnaby': 246,\n",
       " 'choppy': 247,\n",
       " 'scheffer': 248,\n",
       " 'rouged': 249,\n",
       " 'henriksen': 250,\n",
       " 'website': 251,\n",
       " 'meister': 252,\n",
       " 'innit': 253,\n",
       " 'safans': 254,\n",
       " 'disneyland': 255,\n",
       " 'topped': 256,\n",
       " 'tipps': 257,\n",
       " 'implantation': 258,\n",
       " 'retardedness': 259,\n",
       " 'mastery': 260,\n",
       " 'dagobah': 261,\n",
       " 'kiedis': 262,\n",
       " 'experience': 263,\n",
       " 'beasties': 264,\n",
       " 'ebano': 265,\n",
       " 'floozy': 266,\n",
       " 'osenniy': 267,\n",
       " 'leering': 268,\n",
       " 'creaked': 269,\n",
       " 'elemental': 270,\n",
       " 'fierstein': 271,\n",
       " 'vilma': 272,\n",
       " 'couple': 273,\n",
       " 'register': 274,\n",
       " 'viola': 275,\n",
       " 'trimmings': 276,\n",
       " 'weberian': 277,\n",
       " 'vlog': 278,\n",
       " 'privates': 279,\n",
       " 'intermarriage': 280,\n",
       " 'sobers': 281,\n",
       " 'nadira': 282,\n",
       " 'wildsmith': 283,\n",
       " 'crabbe': 284,\n",
       " 'rowboat': 285,\n",
       " 'dunderheads': 286,\n",
       " 'bhajpai': 287,\n",
       " 'deltas': 288,\n",
       " 'housework': 289,\n",
       " 'pide': 290,\n",
       " 'eroticism': 291,\n",
       " 'openly': 292,\n",
       " 'brethren': 293,\n",
       " 'nirmal': 294,\n",
       " 'commissioner': 295,\n",
       " 'gunbelt': 296,\n",
       " 'cassandras': 297,\n",
       " 'railrodder': 298,\n",
       " 'motorway': 299,\n",
       " 'domenico': 300,\n",
       " 'things': 301,\n",
       " 'lifetime': 302,\n",
       " 'oporto': 303,\n",
       " 'hyer': 304,\n",
       " 'yielding': 305,\n",
       " 'domergue': 306,\n",
       " 'abolish': 307,\n",
       " 'emperor': 308,\n",
       " 'tenses': 309,\n",
       " 'starlets': 310,\n",
       " 'tangent': 311,\n",
       " 'fifi': 312,\n",
       " 'sase': 313,\n",
       " 'evacuated': 314,\n",
       " 'definite': 315,\n",
       " 'saving': 316,\n",
       " 'augured': 317,\n",
       " 'ketty': 318,\n",
       " 'paraphrase': 319,\n",
       " 'platform': 320,\n",
       " 'surrounds': 321,\n",
       " 'misshappenings': 322,\n",
       " 'trusty': 323,\n",
       " 'creating': 324,\n",
       " 'fathered': 325,\n",
       " 'spattered': 326,\n",
       " 'karts': 327,\n",
       " 'michale': 328,\n",
       " 'bhisti': 329,\n",
       " 'mandates': 330,\n",
       " 'telegrams': 331,\n",
       " 'wane': 332,\n",
       " 'posher': 333,\n",
       " 'bandages': 334,\n",
       " 'falken': 335,\n",
       " 'grandly': 336,\n",
       " 'doophus': 337,\n",
       " 'prizes': 338,\n",
       " 'wanderng': 339,\n",
       " 'emerged': 340,\n",
       " 'fatigued': 341,\n",
       " 'visionaries': 342,\n",
       " 'razorblade': 343,\n",
       " 'cucacha': 344,\n",
       " 'categorical': 345,\n",
       " 'rosenbaum': 346,\n",
       " 'dribbles': 347,\n",
       " 'yalu': 348,\n",
       " 'houswife': 349,\n",
       " 'farsi': 350,\n",
       " 'carrion': 351,\n",
       " 'reggie': 352,\n",
       " 'sovereign': 353,\n",
       " 'spoilerific': 354,\n",
       " 'smells': 355,\n",
       " 'critter': 356,\n",
       " 'arkansas': 357,\n",
       " 'mellifluousness': 358,\n",
       " 'mamoulian': 359,\n",
       " 'helpings': 360,\n",
       " 'brained': 361,\n",
       " 'special': 362,\n",
       " 'watcheable': 363,\n",
       " 'videotape': 364,\n",
       " 'awwwwww': 365,\n",
       " 'brunda': 366,\n",
       " 'broz': 367,\n",
       " 'probalby': 368,\n",
       " 'drunkenly': 369,\n",
       " 'virtuous': 370,\n",
       " 'blyton': 371,\n",
       " 'attendees': 372,\n",
       " 'jelaousy': 373,\n",
       " 'mrs': 374,\n",
       " 'zoomed': 375,\n",
       " 'averagousity': 376,\n",
       " 'inaccurately': 377,\n",
       " 'jacobi': 378,\n",
       " 'phillipines': 379,\n",
       " 'sanguisga': 380,\n",
       " 'imho': 381,\n",
       " 'bankrupt': 382,\n",
       " 'lancie': 383,\n",
       " 'cadilac': 384,\n",
       " 'serbia': 385,\n",
       " 'screenwriters': 386,\n",
       " 'chummy': 387,\n",
       " 'revolt': 388,\n",
       " 'dumbwaiter': 389,\n",
       " 'benet': 390,\n",
       " 'cronnie': 391,\n",
       " 'ridiculously': 392,\n",
       " 'alison': 393,\n",
       " 'rehabilitated': 394,\n",
       " 'ewers': 395,\n",
       " 'altmanesque': 396,\n",
       " 'buttock': 397,\n",
       " 'swiss': 398,\n",
       " 'dethrone': 399,\n",
       " 'pastand': 400,\n",
       " 'yrds': 401,\n",
       " 'doyleluver': 402,\n",
       " 'sexshooter': 403,\n",
       " 'shootout': 404,\n",
       " 'vampyr': 405,\n",
       " 'attains': 406,\n",
       " 'blackhat': 407,\n",
       " 'hieroglyphic': 408,\n",
       " 'myeres': 409,\n",
       " 'clauses': 410,\n",
       " 'paste': 411,\n",
       " 'vigilance': 412,\n",
       " 'arabs': 413,\n",
       " 'ernie': 414,\n",
       " 'distasteful': 415,\n",
       " 'vildan': 416,\n",
       " 'wallah': 417,\n",
       " 'gojo': 418,\n",
       " 'rami': 419,\n",
       " 'rapidity': 420,\n",
       " 'ratbatspidercrab': 421,\n",
       " 'gaunt': 422,\n",
       " 'disabling': 423,\n",
       " 'deidre': 424,\n",
       " 'specially': 425,\n",
       " 'coasting': 426,\n",
       " 'ogre': 427,\n",
       " 'turners': 428,\n",
       " 'willett': 429,\n",
       " 'pail': 430,\n",
       " 'ality': 431,\n",
       " 'monitoring': 432,\n",
       " 'chiba': 433,\n",
       " 'garment': 434,\n",
       " 'overheated': 435,\n",
       " 'switchblade': 436,\n",
       " 'kiesser': 437,\n",
       " 'polygram': 438,\n",
       " 'robed': 439,\n",
       " 'universally': 440,\n",
       " 'balanchine': 441,\n",
       " 'alienness': 442,\n",
       " 'seawater': 443,\n",
       " 'screened': 444,\n",
       " 'fraternal': 445,\n",
       " 'voluminous': 446,\n",
       " 'drugs': 447,\n",
       " 'afterward': 448,\n",
       " 'testicularly': 449,\n",
       " 'attire': 450,\n",
       " 'inuyasha': 451,\n",
       " 'whales': 452,\n",
       " 'karens': 453,\n",
       " 'pinned': 454,\n",
       " 'satirist': 455,\n",
       " 'proberbial': 456,\n",
       " 'limousine': 457,\n",
       " 'blobby': 458,\n",
       " 'lulu': 459,\n",
       " 'maharishi': 460,\n",
       " 'retellings': 461,\n",
       " 'persists': 462,\n",
       " 'sunbathing': 463,\n",
       " 'joys': 464,\n",
       " 'babysits': 465,\n",
       " 'hurls': 466,\n",
       " 'commenting': 467,\n",
       " 'inflections': 468,\n",
       " 'skateboarding': 469,\n",
       " 'recollects': 470,\n",
       " 'janina': 471,\n",
       " 'hollandish': 472,\n",
       " 'clitarissa': 473,\n",
       " 'thas': 474,\n",
       " 'conchatta': 475,\n",
       " 'coattails': 476,\n",
       " 'psychical': 477,\n",
       " 'wallmart': 478,\n",
       " 'ellipses': 479,\n",
       " 'everybodys': 480,\n",
       " 'discards': 481,\n",
       " 'gumshoe': 482,\n",
       " 'gardosh': 483,\n",
       " 'crapdom': 484,\n",
       " 'buzzy': 485,\n",
       " 'metaldude': 486,\n",
       " 'indicated': 487,\n",
       " 'chocked': 488,\n",
       " 'dpardieu': 489,\n",
       " 'transitioning': 490,\n",
       " 'gastaldi': 491,\n",
       " 'easiest': 492,\n",
       " 'yvette': 493,\n",
       " 'kamerdaschaft': 494,\n",
       " 'roofs': 495,\n",
       " 'verbs': 496,\n",
       " 'besco': 497,\n",
       " 'gentrification': 498,\n",
       " 'sanguine': 499,\n",
       " 'universities': 500,\n",
       " 'drusse': 501,\n",
       " 'calleia': 502,\n",
       " 'dalian': 503,\n",
       " 'mayo': 504,\n",
       " 'concealed': 505,\n",
       " 'scraggly': 506,\n",
       " 'case': 507,\n",
       " 'meaningfulness': 508,\n",
       " 'omits': 509,\n",
       " 'laborer': 510,\n",
       " 'phallus': 511,\n",
       " 'vain': 512,\n",
       " 'thge': 513,\n",
       " 'andalou': 514,\n",
       " 'spokesperson': 515,\n",
       " 'arthritis': 516,\n",
       " 'journeys': 517,\n",
       " 'snappy': 518,\n",
       " 'bowl': 519,\n",
       " 'incompetent': 520,\n",
       " 'fulfills': 521,\n",
       " 'silvestri': 522,\n",
       " 'characterisations': 523,\n",
       " 'caribean': 524,\n",
       " 'arkush': 525,\n",
       " 'pemberton': 526,\n",
       " 'fervour': 527,\n",
       " 'heterosexuals': 528,\n",
       " 'avati': 529,\n",
       " 'boyle': 530,\n",
       " 'gravely': 531,\n",
       " 'kosher': 532,\n",
       " 'combusts': 533,\n",
       " 'dennis': 534,\n",
       " 'deewar': 535,\n",
       " 'problems': 536,\n",
       " 'le': 537,\n",
       " 'pekinpah': 538,\n",
       " 'rustlings': 539,\n",
       " 'caught': 540,\n",
       " 'telegram': 541,\n",
       " 'scatchard': 542,\n",
       " 'restrains': 543,\n",
       " 'towered': 544,\n",
       " 'sprint': 545,\n",
       " 'helmit': 546,\n",
       " 'followers': 547,\n",
       " 'eiffel': 548,\n",
       " 'radely': 549,\n",
       " 'grillo': 550,\n",
       " 'ozone': 551,\n",
       " 'soulfulness': 552,\n",
       " 'their': 553,\n",
       " 'disingenuous': 554,\n",
       " 'akshaya': 555,\n",
       " 'mle': 556,\n",
       " 'pyasa': 557,\n",
       " 'friedo': 558,\n",
       " 'brooklynese': 559,\n",
       " 'realtor': 560,\n",
       " 'whoopie': 561,\n",
       " 'palminteri': 562,\n",
       " 'konec': 563,\n",
       " 'fabricates': 564,\n",
       " 'shimbei': 565,\n",
       " 'blandly': 566,\n",
       " 'consuming': 567,\n",
       " 'parmeshwar': 568,\n",
       " 'reified': 569,\n",
       " 'sciorra': 570,\n",
       " 'discreetly': 571,\n",
       " 'morningstar': 572,\n",
       " 'wilkinson': 573,\n",
       " 'discolored': 574,\n",
       " 'settings': 575,\n",
       " 'mammarian': 576,\n",
       " 'microbiology': 577,\n",
       " 'kleinfeld': 578,\n",
       " 'kolker': 579,\n",
       " 'thorstenson': 580,\n",
       " 'mammal': 581,\n",
       " 'skullduggery': 582,\n",
       " 'rowed': 583,\n",
       " 'couture': 584,\n",
       " 'collete': 585,\n",
       " 'erudite': 586,\n",
       " 'nietsze': 587,\n",
       " 'horrific': 588,\n",
       " 'switcheroo': 589,\n",
       " 'narcissism': 590,\n",
       " 'monters': 591,\n",
       " 'albanians': 592,\n",
       " 'ragbag': 593,\n",
       " 'ameliorated': 594,\n",
       " 'gravitation': 595,\n",
       " 'cpt': 596,\n",
       " 'sneaks': 597,\n",
       " 'favourtie': 598,\n",
       " 'timberlake': 599,\n",
       " 'futuramafan': 600,\n",
       " 'anime': 601,\n",
       " 'ashram': 602,\n",
       " 'discharge': 603,\n",
       " 'schizophreniac': 604,\n",
       " 'hummable': 605,\n",
       " 'teamsters': 606,\n",
       " 'crucifi': 607,\n",
       " 'alongno': 608,\n",
       " 'chirstmastime': 609,\n",
       " 'exudes': 610,\n",
       " 'elisa': 611,\n",
       " 'nicky': 612,\n",
       " 'borek': 613,\n",
       " 'pilger': 614,\n",
       " 'wildest': 615,\n",
       " 'pausing': 616,\n",
       " 'catboy': 617,\n",
       " 'paradice': 618,\n",
       " 'neophyte': 619,\n",
       " 'gaffney': 620,\n",
       " 'shortcuts': 621,\n",
       " 'yorgos': 622,\n",
       " 'annoyances': 623,\n",
       " 'rafael': 624,\n",
       " 'coer': 625,\n",
       " 'jayden': 626,\n",
       " 'crystina': 627,\n",
       " 'ohrt': 628,\n",
       " 'theoscarsblog': 629,\n",
       " 'everybodies': 630,\n",
       " 'fireexplosionsgreat': 631,\n",
       " 'comparisons': 632,\n",
       " 'pota': 633,\n",
       " 'willy': 634,\n",
       " 'assi': 635,\n",
       " 'conformity': 636,\n",
       " 'endgame': 637,\n",
       " 'exhibitionism': 638,\n",
       " 'bakersfeild': 639,\n",
       " 'cabins': 640,\n",
       " 'etcoverfilling': 641,\n",
       " 'whereever': 642,\n",
       " 'warrior': 643,\n",
       " 'suzanna': 644,\n",
       " 'slaughtered': 645,\n",
       " 'balooned': 646,\n",
       " 'tabasco': 647,\n",
       " 'worshipped': 648,\n",
       " 'stiers': 649,\n",
       " 'brownesque': 650,\n",
       " 'sars': 651,\n",
       " 'venn': 652,\n",
       " 'dupery': 653,\n",
       " 'mal': 654,\n",
       " 'alldredge': 655,\n",
       " 'vigalondo': 656,\n",
       " 'robby': 657,\n",
       " 'ews': 658,\n",
       " 'egger': 659,\n",
       " 'roedel': 660,\n",
       " 'umcompromising': 661,\n",
       " 'shandara': 662,\n",
       " 'fanfictions': 663,\n",
       " 'suggest': 664,\n",
       " 'engagements': 665,\n",
       " 'videocassette': 666,\n",
       " 'dessert': 667,\n",
       " 'sipple': 668,\n",
       " 'kerby': 669,\n",
       " 'balfour': 670,\n",
       " 'bludgeons': 671,\n",
       " 'puttingly': 672,\n",
       " 'tetsud': 673,\n",
       " 'gashuin': 674,\n",
       " 'pickard': 675,\n",
       " 'ppppuuuulllleeeeeez': 676,\n",
       " 'sopping': 677,\n",
       " 'geewiz': 678,\n",
       " 'verheyen': 679,\n",
       " 'madagascar': 680,\n",
       " 'citroen': 681,\n",
       " 'jason': 682,\n",
       " 'uninvolved': 683,\n",
       " 'imbroglio': 684,\n",
       " 'orgasm': 685,\n",
       " 'leonid': 686,\n",
       " 'distastefully': 687,\n",
       " 'routh': 688,\n",
       " 'views': 689,\n",
       " 'caricatures': 690,\n",
       " 'headdress': 691,\n",
       " 'adkins': 692,\n",
       " 'zoltan': 693,\n",
       " 'innovatory': 694,\n",
       " 'indescibably': 695,\n",
       " 'defending': 696,\n",
       " 'desktop': 697,\n",
       " 'kodokoo': 698,\n",
       " 'sketchy': 699,\n",
       " 'raises': 700,\n",
       " 'visayas': 701,\n",
       " 'dee': 702,\n",
       " 'yardley': 703,\n",
       " 'llbean': 704,\n",
       " 'orgolini': 705,\n",
       " 'buttered': 706,\n",
       " 'effeminate': 707,\n",
       " 'humpty': 708,\n",
       " 'sugar': 709,\n",
       " 'unbelievers': 710,\n",
       " 'fomentation': 711,\n",
       " 'serve': 712,\n",
       " 'gyllenhaal': 713,\n",
       " 'absorbed': 714,\n",
       " 'bewilder': 715,\n",
       " 'skits': 716,\n",
       " 'vocalize': 717,\n",
       " 'referees': 718,\n",
       " 'surfboards': 719,\n",
       " 'crumple': 720,\n",
       " 'ovaries': 721,\n",
       " 'myia': 722,\n",
       " 'labours': 723,\n",
       " 'sharpville': 724,\n",
       " 'faridany': 725,\n",
       " 'opinionated': 726,\n",
       " 'procure': 727,\n",
       " 'culp': 728,\n",
       " 'liver': 729,\n",
       " 'schiff': 730,\n",
       " 'geologist': 731,\n",
       " 'shading': 732,\n",
       " 'wagnard': 733,\n",
       " 'fawned': 734,\n",
       " 'factor': 735,\n",
       " 'falsification': 736,\n",
       " 'overwhlelming': 737,\n",
       " 'tennyson': 738,\n",
       " 'ziab': 739,\n",
       " 'antipasto': 740,\n",
       " 'avionics': 741,\n",
       " 'dof': 742,\n",
       " 'condos': 743,\n",
       " 'steeleye': 744,\n",
       " 'krisner': 745,\n",
       " 'mofu': 746,\n",
       " 'wilona': 747,\n",
       " 'slimey': 748,\n",
       " 'chaise': 749,\n",
       " 'humbly': 750,\n",
       " 'mundane': 751,\n",
       " 'employ': 752,\n",
       " 'levi': 753,\n",
       " 'nastasja': 754,\n",
       " 'foran': 755,\n",
       " 'tchecky': 756,\n",
       " 'tightens': 757,\n",
       " 'yazaki': 758,\n",
       " 'endearments': 759,\n",
       " 'youngblood': 760,\n",
       " 'waaaaaaaaay': 761,\n",
       " 'databases': 762,\n",
       " 'candles': 763,\n",
       " 'doubling': 764,\n",
       " 'essay': 765,\n",
       " 'wirtanen': 766,\n",
       " 'bobby': 767,\n",
       " 'exploites': 768,\n",
       " 'isdon': 769,\n",
       " 'byrrh': 770,\n",
       " 'kleptomaniac': 771,\n",
       " 'inducing': 772,\n",
       " 'sal': 773,\n",
       " 'looooooooong': 774,\n",
       " 'happyend': 775,\n",
       " 'diluting': 776,\n",
       " 'dissatisfying': 777,\n",
       " 'sceptically': 778,\n",
       " 'luddite': 779,\n",
       " 'wb': 780,\n",
       " 'durward': 781,\n",
       " 'jip': 782,\n",
       " 'bested': 783,\n",
       " 'suppose': 784,\n",
       " 'skers': 785,\n",
       " 'largesse': 786,\n",
       " 'briefed': 787,\n",
       " 'feints': 788,\n",
       " 'yaaawwnnn': 789,\n",
       " 'com': 790,\n",
       " 'archly': 791,\n",
       " 'nechayev': 792,\n",
       " 'crowbar': 793,\n",
       " 'anilji': 794,\n",
       " 'herzegowina': 795,\n",
       " 'habit': 796,\n",
       " 'communicated': 797,\n",
       " 'scuzzlebut': 798,\n",
       " 'inattentiveness': 799,\n",
       " 'quitte': 800,\n",
       " 'peeks': 801,\n",
       " 'mysteriously': 802,\n",
       " 'migraine': 803,\n",
       " 'soothe': 804,\n",
       " 'thomajan': 805,\n",
       " 'titty': 806,\n",
       " 'deceased': 807,\n",
       " 'parochialism': 808,\n",
       " 'grays': 809,\n",
       " 'fatness': 810,\n",
       " 'bulow': 811,\n",
       " 'jazzy': 812,\n",
       " 'hendler': 813,\n",
       " 'demerit': 814,\n",
       " 'occasional': 815,\n",
       " 'elixir': 816,\n",
       " 'deathline': 817,\n",
       " 'capshaw': 818,\n",
       " 'owl': 819,\n",
       " 'purefoy': 820,\n",
       " 'convincingly': 821,\n",
       " 'pedicure': 822,\n",
       " 'lullaby': 823,\n",
       " 'grover': 824,\n",
       " 'hip': 825,\n",
       " 'shown': 826,\n",
       " 'tepper': 827,\n",
       " 'ho': 828,\n",
       " 'housebound': 829,\n",
       " 'confection': 830,\n",
       " 'moovie': 831,\n",
       " 'amg': 832,\n",
       " 'srathairn': 833,\n",
       " 'schmitz': 834,\n",
       " 'armless': 835,\n",
       " 'glanse': 836,\n",
       " 'pachelbel': 837,\n",
       " 'bluhn': 838,\n",
       " 'allowances': 839,\n",
       " 'nominations': 840,\n",
       " 'offputting': 841,\n",
       " 'training': 842,\n",
       " 'hoechlin': 843,\n",
       " 'cavalry': 844,\n",
       " 'rescue': 845,\n",
       " 'throughline': 846,\n",
       " 'congolees': 847,\n",
       " 'wheeled': 848,\n",
       " 'traversing': 849,\n",
       " 'oversimplify': 850,\n",
       " 'emulations': 851,\n",
       " 'tbu': 852,\n",
       " 'triggers': 853,\n",
       " 'jeopardizing': 854,\n",
       " 'quintessential': 855,\n",
       " 'eldon': 856,\n",
       " 'stallone': 857,\n",
       " 'miswrote': 858,\n",
       " 'vili': 859,\n",
       " 'schooner': 860,\n",
       " 'ewa': 861,\n",
       " 'hokey': 862,\n",
       " 'heroin': 863,\n",
       " 'misquoted': 864,\n",
       " 'pest': 865,\n",
       " 'sealer': 866,\n",
       " 'dread': 867,\n",
       " 'alija': 868,\n",
       " 'mend': 869,\n",
       " 'sauna': 870,\n",
       " 'advocacy': 871,\n",
       " 'pyrenees': 872,\n",
       " 'awaited': 873,\n",
       " 'piso': 874,\n",
       " 'unused': 875,\n",
       " 'ambient': 876,\n",
       " 'kunst': 877,\n",
       " 'butchest': 878,\n",
       " 'brow': 879,\n",
       " 'tevis': 880,\n",
       " 'maia': 881,\n",
       " 'ilona': 882,\n",
       " 'dx': 883,\n",
       " 'buoy': 884,\n",
       " 'unselfishness': 885,\n",
       " 'ryoga': 886,\n",
       " 'siriaque': 887,\n",
       " 'knicker': 888,\n",
       " 'affirmed': 889,\n",
       " 'slobbishness': 890,\n",
       " 'end': 891,\n",
       " 'questionthat': 892,\n",
       " 'valkyrie': 893,\n",
       " 'dashed': 894,\n",
       " 'proudest': 895,\n",
       " 'invierno': 896,\n",
       " 'farr': 897,\n",
       " 'distraction': 898,\n",
       " 'acknowledgement': 899,\n",
       " 'greys': 900,\n",
       " 'nuthin': 901,\n",
       " 'fancier': 902,\n",
       " 'edna': 903,\n",
       " 'lexa': 904,\n",
       " 'rippingly': 905,\n",
       " 'cimmerian': 906,\n",
       " 'suresh': 907,\n",
       " 'badminton': 908,\n",
       " 'creature': 909,\n",
       " 'eightball': 910,\n",
       " 'moor': 911,\n",
       " 'downgraded': 912,\n",
       " 'ecoleanings': 913,\n",
       " 'nile': 914,\n",
       " 'rubano': 915,\n",
       " 'inelegant': 916,\n",
       " 'softest': 917,\n",
       " 'watertank': 918,\n",
       " 'advancements': 919,\n",
       " 'attests': 920,\n",
       " 'fakes': 921,\n",
       " 'dustin': 922,\n",
       " 'macquire': 923,\n",
       " 'debriefed': 924,\n",
       " 'engrossed': 925,\n",
       " 'telepath': 926,\n",
       " 'pierpont': 927,\n",
       " 'midwinter': 928,\n",
       " 'underztand': 929,\n",
       " 'dateing': 930,\n",
       " 'billowy': 931,\n",
       " 'forego': 932,\n",
       " 'pummel': 933,\n",
       " 'crooke': 934,\n",
       " 'nickelodean': 935,\n",
       " 'choreographers': 936,\n",
       " 'churned': 937,\n",
       " 'unprofessionally': 938,\n",
       " 'formulated': 939,\n",
       " 'roberte': 940,\n",
       " 'bassinger': 941,\n",
       " 'culture': 942,\n",
       " 'wrangling': 943,\n",
       " 'retina': 944,\n",
       " 'thriteen': 945,\n",
       " 'safety': 946,\n",
       " 'broody': 947,\n",
       " 'scaramouche': 948,\n",
       " 'brontosaurus': 949,\n",
       " 'ccafs': 950,\n",
       " 'clamor': 951,\n",
       " 'barris': 952,\n",
       " 'bates': 953,\n",
       " 'monotone': 954,\n",
       " 'infernal': 955,\n",
       " 'trounced': 956,\n",
       " 'unpalatable': 957,\n",
       " 'gwyneth': 958,\n",
       " 'engaging': 959,\n",
       " 'naissance': 960,\n",
       " 'disordered': 961,\n",
       " 'cheese': 962,\n",
       " 'gras': 963,\n",
       " 'blablabla': 964,\n",
       " 'troupe': 965,\n",
       " 'intensely': 966,\n",
       " 'barone': 967,\n",
       " 'coco': 968,\n",
       " 'peculiar': 969,\n",
       " 'banana': 970,\n",
       " 'vagabond': 971,\n",
       " 'chez': 972,\n",
       " 'truckload': 973,\n",
       " 'earle': 974,\n",
       " 'plagiary': 975,\n",
       " 'redden': 976,\n",
       " 'oppressive': 977,\n",
       " 'terrify': 978,\n",
       " 'yetis': 979,\n",
       " 'terpsichorean': 980,\n",
       " 'gatesville': 981,\n",
       " 'chungking': 982,\n",
       " 'khang': 983,\n",
       " 'prosperous': 984,\n",
       " 'tibor': 985,\n",
       " 'ates': 986,\n",
       " 'sedated': 987,\n",
       " 'quandary': 988,\n",
       " 'cusp': 989,\n",
       " 'nathaniel': 990,\n",
       " 'detail': 991,\n",
       " 'hooted': 992,\n",
       " 'mongering': 993,\n",
       " 'names': 994,\n",
       " 'swedlow': 995,\n",
       " 'silsby': 996,\n",
       " 'donitz': 997,\n",
       " 'vining': 998,\n",
       " 'ltd': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un diccionario que tiene como key la palabra y como valor el índice asociado\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "    \n",
    "word2index\n",
    "\n",
    "# función que crea un diccionario con las palabras del vocabulario de las reviewz y asigna a cada palabra su índice en el \n",
    "# vocabulario de palabras, cuando calculemos los vectores las columnas asociadas a cada palabra coincidirán con estos índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00djBLcWLe3-"
   },
   "source": [
    "#### Cuarto paso: crear la función que dada una crítica devuelve un vector contando la frecuencia de las palabras utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Iov2PNeLEw5"
   },
   "outputs": [],
   "source": [
    "## Rellena la función que para crítica devuelve el vector asociado aplicando bag of words\n",
    "def bag_of_words(review):\n",
    "  v = np.zeros(vocab_size)\n",
    "  for word in review.split(\" \"):\n",
    "    v[word2index[word]] += 1\n",
    "  return v\n",
    "\n",
    "# definimos función \"bag_of_words()\" que saca vector para cada review con la \n",
    "# frecuencia de las palabras que aparecen en esa review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uR3jCvuSBrf"
   },
   "outputs": [],
   "source": [
    " reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUK2EgynrIe5",
    "outputId": "d6c3cf2c-2734-4264-ee8a-d9b340ecc7b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlrsCmqUq52Z",
    "outputId": "f0299d26-05a5-4630-f4e2-82d330dfca56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(reviews[0])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xRxKg8jorVrd",
    "outputId": "896660c0-29b7-4a3a-e908-2fd38a1edd9f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2iUM_MeSGkP",
    "outputId": "e609f6ab-fac3-45ff-fa5f-eb7c301d4655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['']\n",
    "\n",
    "# palabra con indice=0 del vocabulario es \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_k9F2QfskNt",
    "outputId": "b9fdc09a-3e95-4d15-a72b-273f05430cf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(reviews[0])[0]\n",
    "\n",
    "# de esta forma estamos revisando para la \"review_0\" cuantas veces aparece (18 veces) la palabra con índice=0 de nuestro \n",
    "# vocabulario\n",
    "# palabra con indice=0 del vocabulario es \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ASg9r1ga6en",
    "outputId": "002ad376-e1c5-458e-c5f2-ae337850b725"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43671"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index[\"bromwell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7BOLYxRMJFL",
    "outputId": "a7eadc77-a4b2-46cf-dac9-a5e0a1386288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(reviews[0])[12891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e-pUBV5ay1t",
    "outputId": "ed57c125-29d7-44e6-dec8-b7c0beeabd59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74074,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(reviews[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zy1Su0ENDzb"
   },
   "source": [
    "#### Quinto paso: el target de nuestro modelo serán 1s y 0s. Vamos a crear una función que convierta los cadenas POSITIVE y NEGATIVE a 1 y 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUQ52KX3MLfC"
   },
   "outputs": [],
   "source": [
    "## Rellena la función para que dada la etiqueta en forma de cadena devuelve el entero asociado\n",
    "def target_numerico(label):\n",
    "  if label == \"POSITIVE\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXFHGGG8Ngf2",
    "outputId": "13fe9986-dadb-4b6e-eef5-a519ab8caeb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_numerico(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3socGi2cP_v4"
   },
   "source": [
    "#### Sexto paso: dividimos los datos que tenemos en train y test (esta vez lo hacemos a ojo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hiy_hHiNQKHV",
    "outputId": "ef6c0e94-c056-44af-d563-dd61633004b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "training_size = 5000\n",
    "test_size = 10000\n",
    "training_rev = reviews[:training_size]\n",
    "training_lab = labels[:training_size]\n",
    "test_rev = reviews[-test_size:]\n",
    "test_lab = labels[-test_size:]\n",
    "print(len(training_lab))\n",
    "print(len(test_lab))\n",
    "\n",
    "# dividimos dataset en \"train\" y \"test\" para entrenar el modelo y luego comprobar su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd6kzIovTxEZ",
    "outputId": "7872b7c0-80eb-4ec2-9f17-c2db5e31f2ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who in their right mind does anything so stupid as this movie   br    br   accidental killing of a security guard . . . characters that are so two dimensional that a two year old could have painted drawn them . . . and better . . .  br    br   a red toolbox of death  please . . . .  br    br   hypothermic weak thugs . . .  br    br   acting from hell . . .  br    br   stylistically this movie shifts between teen comedy  thriller  voyeurism and . . . female . . .  uhm  rambo   br    br   unbelievable and it  s an insult to any thinking person . do not watch  walk away it  s more horrible than you may imagine . . .  br    br   and on top of it all it  s trying to be hip by being overly graphic in it  s violence . . .  br    br   mrs montford shoot  em up was fun and funny  this is just pathetic and terrible . good luck next time .     \n",
      "who in their right mind does anything so stupid as this movie   br    br   accidental killing of a security guard . . . characters that are so two dimensional that a two year old could have painted drawn them . . . and better . . .  br    br   a red toolbox of death  please . . . .  br    br   hypothermic weak thugs . . .  br    br   acting from hell . . .  br    br   stylistically this movie shifts between teen comedy  thriller  voyeurism and . . . female . . .  uhm  rambo   br    br   unbelievable and it  s an insult to any thinking person . do not watch  walk away it  s more horrible than you may imagine . . .  br    br   and on top of it all it  s trying to be hip by being overly graphic in it  s violence . . .  br    br   mrs montford shoot  em up was fun and funny  this is just pathetic and terrible . good luck next time .     \n"
     ]
    }
   ],
   "source": [
    "print(training_rev[training_size-1])\n",
    "print(reviews[training_size-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E61D-jvbT_kc",
    "outputId": "a7dc51e6-6c31-496d-ff16-6c829f3a1f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this documentary  now available free on video . google . com  is a fantastic demonstration of the power of ordinary people to overcome injustice . everyone must see this .  br    br   chavez was elected in a landslide vote in     . his platform was to divert the fantastic oil wealth from the    middle class to the    poor . he banned foreign drift net fishing in venezuelan waters . he sent       cuban doctors to the slums to treat the sick for free . he wiped out illiteracy and set up new free universities .  br    br   but it was his    tax on oil company profits that got him in trouble with the bush administration . in      while irish film makers kim bartley and donnacha o  briain were interviewing chavez inside the presidential palace about his social programs  a cia backed coup was launched . with the cameras rolling  chavez was captured and flown out of the country . it was announced on national tv that he had  resigned  .  br    br   but the poor of venezuela didn  t believe the media . they went to the palace in their millions and demanded that chavez be returned . in the face of such overwhelming numbers  the military turned on the coup leaders and the plotters fled to the us . chavez was rescued by military helicopter and returned to jubilation .  \n",
      "this documentary  now available free on video . google . com  is a fantastic demonstration of the power of ordinary people to overcome injustice . everyone must see this .  br    br   chavez was elected in a landslide vote in     . his platform was to divert the fantastic oil wealth from the    middle class to the    poor . he banned foreign drift net fishing in venezuelan waters . he sent       cuban doctors to the slums to treat the sick for free . he wiped out illiteracy and set up new free universities .  br    br   but it was his    tax on oil company profits that got him in trouble with the bush administration . in      while irish film makers kim bartley and donnacha o  briain were interviewing chavez inside the presidential palace about his social programs  a cia backed coup was launched . with the cameras rolling  chavez was captured and flown out of the country . it was announced on national tv that he had  resigned  .  br    br   but the poor of venezuela didn  t believe the media . they went to the palace in their millions and demanded that chavez be returned . in the face of such overwhelming numbers  the military turned on the coup leaders and the plotters fled to the us . chavez was rescued by military helicopter and returned to jubilation .  \n"
     ]
    }
   ],
   "source": [
    "print(test_rev[0])\n",
    "print(reviews[-test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wjjnhbmQ2bR"
   },
   "source": [
    "#### Séptimo paso: calculamos las matrices de entrenamiento y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CnlYbNnNkdA",
    "outputId": "a0ec7853-df37-4986-87ca-081c4b531edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 74074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [78.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.empty((len(training_rev), vocab_size))\n",
    "print(X_train.shape)\n",
    "### Rellena X aquí\n",
    "for i in range(len(training_rev)):\n",
    "  X_train[i] = bag_of_words(training_rev[i])\n",
    "\n",
    "X_train[:3]\n",
    "\n",
    "# creamos matriz de \"train\" añadiendo los vectores de las reviews del conjunto de entrenamiento definido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDfnC2WRVkAA",
    "outputId": "35657990-a84e-43b0-e9e4-166fc47e7b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 74074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [72.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [28.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.empty((len(test_rev), vocab_size))\n",
    "print(X_test.shape)\n",
    "# Rellena X_test aquí\n",
    "for i in range(len(test_rev)):\n",
    "  X_test[i] = bag_of_words(test_rev[i])\n",
    "\n",
    "X_test[:3]\n",
    "\n",
    "# creamos matriz de \"test\" añadiendo los vectores de las reviews del conjunto de entrenamiento definido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dRHQFKVPLaB",
    "outputId": "c6482dfa-d71b-4fbd-9558-dd63f2b359d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.empty((len(training_lab),))\n",
    "print(y_train.shape)\n",
    "# Rellena y aquí\n",
    "for i in range(len(training_lab)):\n",
    "  y_train[i] = target_numerico(training_lab[i])\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQ8H8PfQVuiC",
    "outputId": "3e080ba1-ac45-44d0-a1b7-86994baa6b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.empty((len(test_lab),))\n",
    "print(y_test.shape)\n",
    "# Rellena y_test aquí\n",
    "for i in range(len(test_lab)):\n",
    "  y_test[i] = target_numerico(test_lab[i])\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BUgNbNaVZQI"
   },
   "source": [
    "#### Octavo paso: entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "418HbjvnS3R6"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFw3UoZDTNrz",
    "outputId": "d244f725-60d7-4804-a07e-ffbd9e2596a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbMoVIvVd37"
   },
   "source": [
    "#### Noveno paso: aplicamos el predict sobre el conjunto de test y vemos qué tal funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ew7DEftTOnr"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jz8FOER4VSYf",
    "outputId": "2d4c626f-202b-4872-af04-bb975891fb82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EMDdavGWEs-",
    "outputId": "d9ad5790-7fab-4a0b-ae8f-2dcb95dca791"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8397"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTVPXI4TWHvS",
    "outputId": "5efe9542-8f8c-46af-a970-f06c9931498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4311  689]\n",
      " [ 914 4086]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGy6v14K-Ovy",
    "outputId": "78e9b057-4395-43f2-fe1e-346d5d60bfc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.84      5000\n",
      "         1.0       0.86      0.82      0.84      5000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1_6xKsU-cOe"
   },
   "source": [
    "#### Decimo paso: preparamos el código para probar el modelo con cadenas nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Melhwgn7-YVv"
   },
   "outputs": [],
   "source": [
    "# Rellena la función para, dada una crítica, aplicar el modelo que hemos entrenado\n",
    "# e imprimir POSITIVE/NEGATIVE\n",
    "def sentiment_analysis(review):\n",
    "  vector_input = np.empty((1, vocab_size))\n",
    "  vector_input[0] = bag_of_words(review)\n",
    "  pred = model.predict(vector_input)\n",
    "  if pred == 1:\n",
    "    print(\"POSITIVE\")\n",
    "  else:\n",
    "    print(\"NEGATIVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83AM8es9_oNl",
    "outputId": "ee6aa78c-4a71-4660-c863-eeadc5543da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('movie bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVkYqDqC_rLm",
    "outputId": "431cf311-d03e-4ed5-f681-caa84e129c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('not horrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "Rj8IWCGxAHNZ",
    "outputId": "683d9606-13b2-4387-ea05-b41fbd40f2fa"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-9366ae08c6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'España good'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-517c95758637>\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvector_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mvector_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-e45e25126178>\u001b[0m in \u001b[0;36mbag_of_words\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'España'"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('España good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oUKhEDkASes"
   },
   "source": [
    "¿Qué hacemos con el error que se obtiene al meter una palabra que no está en el vocabulario? Solucionar este error es parte de la práctica de la asignatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AqmOcyQMd_A"
   },
   "outputs": [],
   "source": [
    "# al incluir una palabra que no ha visto en train, el modelo se rompe y devuelve un error\n",
    "# resolver el problema para que no de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "LxIV-DyqAKUF",
    "outputId": "24ca1d7e-4f45-499e-d8aa-bcb063ada7c1"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f7d6180cd8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-517c95758637>\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvector_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mvector_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-e45e25126178>\u001b[0m in \u001b[0;36mbag_of_words\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Cool'"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('Cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDNO9LHVAp6E"
   },
   "source": [
    "Pero si Cool si es una palabra inglesa. ¿Qué ocurre? ¿Cómo lo solucionamos? Esto también es parte de la práctica de la asignatura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cphmPCyuA3VS"
   },
   "outputs": [],
   "source": [
    "# retocar fórmulas/funciones definidas para que no se rompa el modelo\n",
    "# resolver el problema para que no de error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc7FXcVmz347"
   },
   "source": [
    "#### SOLUCIÓN DE ERRORES: Definición de una nueva función para la aplicación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Qu_MxUPMe35"
   },
   "outputs": [],
   "source": [
    "# IDEA (alguna palabra de la nueva review no está o no coincide exactamente con las palabras del diccionario)\n",
    "\n",
    "# FUNCIÓN DE APLICACIÓN DEL MODELO:\n",
    "# Revisar la función de aplicación del modelo para que sea capaz de analizar las palabras de la review nueva.\n",
    "# Comprobar casos:\n",
    "#    a) palabra pertenece a vocabulario \n",
    "#    b) palabra pertenece al vocabulario pero con variación de mayúscula/minúscula inicial \n",
    "#        (informar al usuario de que se transforma la palabra e incluir transformación en el análisis)\n",
    "#    c) palabra no pertenece al vocabulario\n",
    "#        (informar al usuario de que se descarta la palabra y no se tendrá en cuenta para el análisis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FII2RbAkMe6i"
   },
   "outputs": [],
   "source": [
    "# Rellena la función para, dada una crítica, aplicar el modelo que hemos entrenado e imprimir POSITIVE/NEGATIVE\n",
    "\n",
    "def rev_sentiment_analysis(review):\n",
    "  vector_input = np.empty((1, vocab_size))\n",
    "  review_vocab = []\n",
    "  review_transfvocab = []\n",
    "  review_notvocab = []\n",
    "\n",
    "  # Análisis previo de las palabras de la nueva review\n",
    "  for word in review.split(\" \"):\n",
    "    if word in vocab:\n",
    "      review_vocab.append(word)\n",
    "      continue\n",
    "    else: \n",
    "      if word.lower() in vocab:\n",
    "        review_transfvocab.append(word.lower())\n",
    "        continue\n",
    "      if word.capitalize() in vocab:\n",
    "        review_transfvocab.append(word.capitalize())\n",
    "        continue\n",
    "      else:\n",
    "        review_notvocab.append(word)\n",
    "\n",
    "  review = \" \".join(list(review_vocab + review_transfvocab))\n",
    "  print(' - Palabras transformadas (mayúsculas/minúsculas): ', review_transfvocab)\n",
    "  print(' - Palabras descartadas (no contenidas en vocabulario de \"train\"): ', review_notvocab)\n",
    "  \n",
    "  # Comprobación y aplicación del modelo\n",
    "  if len(review) == 0:\n",
    "    print('-'*100)\n",
    "    print('No se puede realizar el análisis de sentimiento de la review introducida.')\n",
    "    print('Ninguna de las palabras incluidas en la review está contenida en el vocabulario de \"train\" del modelo.')\n",
    "  else:\n",
    "    print(' - Palabras consideradas para el análisis de sentimiento: ', review.split(\" \"))\n",
    "    print('-'*100)\n",
    "    vector_input[0] = bag_of_words(review)\n",
    "    pred = model.predict(vector_input)\n",
    "    if pred == 1:\n",
    "      print(\"POSITIVE\")\n",
    "    else:\n",
    "      print(\"NEGATIVE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuurSogh9SL3",
    "outputId": "7de73719-8468-4524-fa29-92e6eafbac3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  ['polanski']\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  ['España', ',']\n",
      " - Palabras consideradas para el análisis de sentimiento:  ['good', 'film', 'polanski', 'polanski']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis('Polanski España good film , polanski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bci75gcVIEii",
    "outputId": "f7f0dccc-021a-402e-a2e5-91f3c453432c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  []\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  [',']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "No se puede realizar el análisis de sentimiento de la review introducida.\n",
      "Ninguna de las palabras incluidas en la review está contenida en el vocabulario de \"train\" del modelo.\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPiRYRCczpAQ",
    "outputId": "ec25c87a-61b9-489b-f8b7-48167c82f0ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  []\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  []\n",
      " - Palabras consideradas para el análisis de sentimiento:  ['movie', 'bad']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis('movie bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJJC0C8vzpAS",
    "outputId": "01c92ea4-0698-45ce-dcaa-a19ed1e0f36d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  []\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  []\n",
      " - Palabras consideradas para el análisis de sentimiento:  ['not', 'horrible']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis('not horrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RsSguZ2zwVw",
    "outputId": "67b1cc06-3502-44e7-b479-c6326f781dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  []\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  ['España']\n",
      " - Palabras consideradas para el análisis de sentimiento:  ['good']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis('España good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwtMfeCgzq8h",
    "outputId": "93e1b9c2-666a-445e-b218-5d51d88b0350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Palabras transformadas (mayúsculas/minúsculas):  ['cool']\n",
      " - Palabras descartadas (no contenidas en vocabulario de \"train\"):  []\n",
      " - Palabras consideradas para el análisis de sentimiento:  ['cool']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "rev_sentiment_analysis('Cool')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d5Y0tolWGdIo",
    "sLGTusxtGV87",
    "viJr7UXGeVbu",
    "1CquUDSegmpV",
    "hD8mLKkKJOaL",
    "OeneoUAXKRe5",
    "S-wjmc3TKl7n",
    "00djBLcWLe3-",
    "-zy1Su0ENDzb",
    "3socGi2cP_v4",
    "8wjjnhbmQ2bR",
    "0BUgNbNaVZQI",
    "tHbMoVIvVd37",
    "T1_6xKsU-cOe"
   ],
   "machine_shape": "hm",
   "name": "6_Clasificacion_Textos_SOLUCION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
